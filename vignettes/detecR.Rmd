---
title: "Using DetectR"
author: "Pierre-Carl Langlais, JoÃ«l Gombin"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r config, echo=FALSE}
library("knitr")
opts_chunk$set(cache=TRUE)
```


```{r load}
library("tidyverse")
library("lubridate")
library("detectR")
```

First we clean up the piwick logs. Two variables allow to filter the dataset more effectively:
- The minimum number of absolute days of recorded logs for each url (in order to get a working model)
- The relative number of recording days viz. the first time the url appears in the logs (which may reflect its publication date)

```{r}
logs_board <- get_aggregated_piwick("../../../../atelier-data/complete_log_clean.csv", absolute_days=20, relative_days=0.9)
```

Then we get the main variable of time variability, which includes seasonal (weekly) variation, general trend on revues.org.

```{r}

times_decomposition_board <- get_calendar_time_series(logs_board)
```

We compensate the recorded view with the time variability variables.
```{r}
logs_board$aggregated_frequent <- correct_time_series(logs_board$aggregated_frequent, times_decomposition_board)
```

We proceed with anomaly detection, using a restricted cubic spline with 3 knots.

```{r, warning=FALSE}
anomaly_detection <- detection_anomalies_rcs(logs_board$aggregated_frequent)
```

We can get a graph of the anomalies for one article

```{r, fig.width=5}
graph_anomalies_rcs(anomaly_detection, "mots.revues.org/21665")
```

It is also possible to get the same with adjusted size for sigma ratio for each anomaly (ie to what extent does it affect the variable)
```{r, fig.width=5}
graph_anomalies_rcs(anomaly_detection, "asiecentrale.revues.org/488", show_sigma = TRUE)
```
